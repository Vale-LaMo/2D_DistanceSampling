---
title: "Density surface modelling"
params:
  seed_no: 16
  trunc_perp_dist: 5
  trunc_forw_dist_m: 150
output:
  html_document:
    df_print: paged
---

```{r packages, message=FALSE}
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages())) 
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
```

```{r functions}
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
```



# Data preparation: impala

## Data import

First of all, we need to prepare the data for the following DSM analysis.
We need three data.frames:

- **segdata** holds the segment data (transects “chopped” into segments), with all the covariates
- **obsdata** obsdata links the distance data (already used in the previous step of the analysis to fit the detection function) to the segments
- **preddata** holds the prediction grid (which includes all the necessary covariates)


<!-- The dataset (Excel file) should include the following columns (order matters):    -->

<!-- - `area`: surface of the study area, in km2 -->
<!-- - `transect`: transect label (it could be a number or a letter) -->
<!-- - `transect_length`: length of the transect, in m -->
<!-- - `obs_time`: date and time stamp (optional) -->
<!-- - `X_observer`: x-coord of the observer (optional) -->
<!-- - `Y_observer`: y-coord of the observer (optional) -->
<!-- - `detected`: a field whose value is 1 in caso of detection of a group of animals, 0 otherwise -->
<!-- - `cluster_size`: number of animals in the group (optional, only if the group has been detected) -->
<!-- - `perp_dist`: perpedicular distance to the observer (optional, only if the group has been detected) -->
<!-- - `forw_dist`: forward distance to the observer (optional, only if the group has been detected) -->
<!-- - `id_record`: a progressive number to identify each record -->
<!-- All optional fields can have empty cells (or *NA*) in the Excel file. On the contrary, *NA*s are not admitted in the fields: `area`, `transect`, `transect_length`, `detected`, `id_record`. -->

*Please note that when reading the file, we specify the column types: make sure to maintain the recommended order of the columns to avoid errors in the procedure; additional columns could of course be added, or the order changed, but then you will have to modify the `col_types` argument accordingly*

```{r segdata-loading}
#### Load dataset
segdata <- read_excel("data/impala_segmenti_vlm.xlsx",
                      #sheet="template_dataset",
                      col_types = c(rep("text", 2),
                                    rep("numeric", 3),
                                    "text",
                                    rep("numeric", 5)))
head(segdata)
```



```{r}
obsdata <- read_excel("data/obsdata.xlsx",
                      #sheet="template_dataset",
                      col_types = c("numeric",
                                    "text",
                                    rep("numeric", 3)))
head(obsdata)
```


```{r}
# please note that data_trunc comes from 00_intro
load("output/data_trunc.RData")
load("output/fitVU.RData")
left_join(obsdata, data_trunc, by = "object") %>% 
  dplyr::select(object:Effort, cluster_size, perp_dist) %>% 
  dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata

obsdata %>% 
  mutate(ddfobj = 1) -> obsdata
segdata %>% 
  mutate(ddfobj = 1) -> segdata

# dsm.xy <- dsm(count~s(x,y), ddf.obj=fitVU, unique(segdata), obsdata, method="REML")
formula <- abundance.est~s(x,y)
ddf.obj = fitVU
ddfobject = fitVU
segment.data = unique(segdata)
observation.data = obsdata
method = "REML"
segment.area = NULL
group = TRUE
availability = 1
convert.units = 1
response = "abundance.est"
engine = "gam"

# dsm.xy <- dsm_temp(abundance.est~s(x,y), ddf.obj=fitVU, unique(segdata), obsdata, method="REML")
# summary(dsm.xy)
```


```{r}
est = fitVU

Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
# x=x[x>=0 & x<=w]
f.x=p.x.std=adbnTRUE=0
# gridx=seq(1e-10,w,length=100)
arrange(obsdata, distance) %>% 
  dplyr::select(object, distance) %>% 
  na.omit() -> gridx.df

# p.xpifit=p.pi.x(x=data_clean$perp_dist, y = data_clean$forw_dist,b,hr,ystart,pi.x,logphi,w)
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
                  ,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value 
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)

bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
```


```{r}
#' @author David Lawrence Miller
check.cols <- function(ddf.obj, segment.data, observation.data, segment.area){

  ## check that the columns are there
  checks <- list(segment.data = c("Effort", "Sample.Label"),
                observation.data = c("object", "Sample.Label", "size",
                                    "distance"))

  # don't need to check distance if we don't have a detection function
  if(is.null(ddf.obj)){
    checks$observation.data <- checks$observation.data[checks$observation.data!=
                                                       "distance"]
  }

  if(!is.null(segment.area)){
    checks$segment.data <- checks$segment.data[checks$segment.data != "Effort"]
  }

  for(i in seq_len(length(checks))){
    check.res <- checks[[i]] %in% names(get(names(checks)[[i]]))
    if(any(!check.res)){

      stop(paste0("Column(s) \"",
                  paste(checks[[i]][!check.res],collapse="\", \""),
                  "\" not found in ", names(checks)[[i]],
                  ".\n  Check ?\"dsm-data\"."))
    }
  }

  ## check that Sample.Label is unique
  if(length(segment.data$Sample.Label)!=length(
                            unique(segment.data$Sample.Label))){
    warning("'Sample.Labels are non-unique in segment data!")
  }

  invisible()
}
```



```{r}
#' @importFrom stats aggregate
# make.data_vlm <- function(response, ddfobject, segdata, obsdata, group,
#                       convert.units, availability, segment.area,
#                       family){

  # probably want to do something smart here...
  seglength.name <- 'Effort'
  segnum.name <- 'Sample.Label'
  distance.name <- 'distance'
  cluster.name <- 'size'

  # avoid irritating "tibble" issues
  segdata <- data.frame(segdata)
  obsdata <- data.frame(obsdata)

  # matching doesn't work later if we don't ensure character labels
  obsdata$object <- as.character(obsdata$object)
  obsdata$Sample.Label <- as.character(obsdata$Sample.Label)
  segdata$Sample.Label <- as.character(segdata$Sample.Label)

  # Estimating group abundance/density
  if(group){
    obsdata[, cluster.name][obsdata[, cluster.name] > 0] <- 1
  }

  # for single ddfs, make a list of 1
  # if(any(c("ddf", "dsmodel")  %in% class(ddfobject))){
    ddfobject <- list(ddfobject)
    segdata$ddfobj <- 1
    obsdata$ddfobj <- 1
  # }else{
  #   if(!any("ddfobj" %in% names(segdata))){
  #     stop("If there are multiple detection functions there must be a column named \"ddfobj\" in the segment and observation data.frame, see ?\"dsm-data\"")
  #   }
  # }

  # iterate over the list of ddfs
  full_obsdata <- c()
  segdata$segment.area <- NA
  segdata$width <- NA

  # deal with availability
  if(response == "density.est"){
    if(!(length(availability) %in% c(1, nrow(obsdata)))){
      stop("Length of 'availability' must be 1 or 'obsdata' rows")
    }
    obsdata$availability <- availability
  }else if(response == "count"){
    if(!(length(availability) %in% c(1, nrow(segdata)))){
      stop("Length of 'availability' must be 1 or 'segdata' rows")
    }
    segdata$availability <- availability
  }else if(response == "abundance.est"){
    if(!(length(availability) %in% c(1, nrow(obsdata)))){
      stop("Length of 'availability' must be 1 or 'obsdata' rows")
    }
    obsdata$availability <- availability
  }

  for(i in seq_along(ddfobject)){

    this_ddf <- ddfobject[[i]]

    # make this a mrds ddf object if we had a Distance one
    if(all(class(this_ddf) == "dsmodel")){
      this_ddf <- this_ddf$ddf
      ddfobject[[i]] <- this_ddf
    }

    # grab the probabilities of detection
    # fitted.p <- fitted(this_ddf)
    fitted.p <- p.xfit.std

    # remove observations which were not in the detection function
    if(!("ddfobj" %in% names(obsdata))){
      stop("No ddfobj column in observation data")
    }
    # this_obsdata <- obsdata[obsdata[["ddfobj"]]==i, ]
    this_obsdata <- filter(obsdata, distance <= w)

    # Check that observations are between left and right truncation
    # warning only -- observations are excluded below
    # No truncation check for strip transects
    if(any(this_obsdata[, distance.name] > this_ddf$w)){
    # if(any(this_obsdata[, distance.name] > this_ddf$meta.data$width)){
      warning(paste("Some observations are outside of detection function", i,
              "truncation!"))
    }

    # reorder the fitted ps, match the ordering in obsdata
    # put this in a column of this_obsdata
    fitted.p.df$object <- as.character(fitted.p.df$object)
    left_join(this_obsdata, fitted.p.df[,c("object","p")], by="object") -> this_obsdata
    # this_obsdata$p <- fitted.p[match(this_obsdata$object, names(fitted.p))]

    # calculate the "width" of the transect, make sure we get it right
    # if we are doing left truncation
    width <- this_ddf$w
    if(!is.null(this_ddf$meta.data$left)){
      width <- width - this_ddf$meta.data$left
    }
    segdata$width[segdata$ddfobj==i] <- width

    # what if there are no matches? Perhaps this is due to the object
    # numbers being wrong? (HINT: yes.)
    if(nrow(this_obsdata) == 0){
      stop(paste("No observations in detection function", i,
                 "matched those in observation table. Check the \"object\" column."))
    }

    # # make sure that the right columns are in the obsdata
    # if(this_ddf$method %in% c("io", "trial")){
    #   if(!("observer" %in% names(this_obsdata))){
    #     stop("obsdata must have a column named observer")
    #   }else{
    #     if((this_ddf$method == "trial") && !all(this_obsdata$observer==1)){
    #       stop("Only observer 1 data is needed for obsdata with trial mode")
    #     }
    #   }
    # }

    # # depending on the detection function (and its data format)
    # # we need a different subset of obsdata
    # # ds = all detections
    # # io = only unique obsns
    # # trial = only obs 1
    # if(this_ddf$method == "io"){
    #   if(any(duplicated(this_obsdata$object))){
    #     stop(paste0("Some object IDs are duplicated in observation data for detection function model ", i, " only unique IDs are required for observation data for io models"))
    #   }
    # }else if(this_ddf$method == "trial"){
    #   this_obsdata <- this_obsdata[this_obsdata[["observer"]] == 1, ]
    # }

    # bind this to the full data
    full_obsdata <- rbind(full_obsdata, this_obsdata)

    # set the segment area for this detection function in the segdata
    # if(this_ddf$meta.data$point){
    #   # here "Effort" is number of visits
    #   segdata$segment.area[segdata$ddfobj==i] <- pi *
    #     segdata$width[segdata$ddfobj==i]^2 *
    #     segdata[, seglength.name][segdata$ddfobj==i]
    # }else{
    # line transects
      segdata$segment.area[segdata$ddfobj==i] <- 2 *
        segdata[, seglength.name][segdata$ddfobj==i] *
        segdata$width[segdata$ddfobj==i]
    }


  # set the full observation data
  obsdata <- full_obsdata

  # set the segment area in the data
  if(!is.null(segment.area)){
    segdata$segment.area <- segment.area
  }


  ## Aggregate response values of the sightings over segments
  if(response == "density.est"){
    responsedata <- aggregate(obsdata[, cluster.name]/
                              (obsdata$p * obsdata$availability),
                              list(obsdata[, segnum.name]), sum)
    off.set <- "none"
  }else if(response == "count"){
    responsedata <- aggregate(obsdata[, cluster.name],
                              list(obsdata[, segnum.name]), sum)
    off.set <- "eff.area"
  }else if(response == "abundance.est"){
    responsedata <- aggregate(obsdata[, cluster.name]/
                              (obsdata$p * obsdata$availability),
                              list(obsdata[, segnum.name]), sum)
    off.set <- "area"
  }


  ## warn if any observations were not allocated
  responsecheck <- aggregate(obsdata[, cluster.name],
                             list(obsdata[, segnum.name]), sum)
  if(sum(obsdata[, cluster.name]) != sum(responsecheck[, 2])){
    message(paste0("Some observations were not allocated to segments!\n",
                   "Check that Sample.Labels match"))
  }

  # name the response data columns
  names(responsedata) <- c(segnum.name, response)

  # if the Sample.Labels don't match at all then we need to stop, nothing
  # can work as all the response values will be zero
  if(!any(segdata[, segnum.name] %in% responsedata[, segnum.name])){
    stop("No matches between segment and observation data.frame Sample.Labels!")
  }

  # Next merge the response variable with the segment records and any
  # response variable that is NA should be assigned 0 because these
  # occur due to 0 sightings
  dat <- merge(segdata, responsedata, by=segnum.name, all.x=TRUE)
  dat[, response][is.na(dat[, response])] <- 0

  # for the offsets with effective area, need to make sure that
  # the ps match the segments
  if(off.set == "eff.area"){
    dat$p <- NA
    for(i in seq_along(ddfobject)){
      this_ddf <- ddfobject[[i]]

      # get all the covariates in this model
      # df_vars <- all_df_vars(this_ddf)
      df_vars <- 0

      if("fake_ddf" %in% class(this_ddf)){
        # strip transect
        dat[dat$ddfobj == i, ]$p <- 1
      }else if(length(df_vars) == 0){
        # if there are no covariates, and all the fitted ps are the same
        # then just duplicate that value enough times for the segments
        dat[dat$ddfobj == i, ]$p <- rep(fitted(this_ddf)[1],
                                        nrow(dat[dat$ddfobj == i, ]))
      }else if(this_ddf$method %in% c("ds", "io", "trial")){
        # get all the covariates in this model
        # df_vars <- all_df_vars(this_ddf)
        df_vars <- NULL

        # check these vars are in the segment table
        if(!all(df_vars %in% colnames(dat))){
          stop(paste0("Detection function covariates are not in the segment data",
                      "\n  Missing: ", df_vars[!(df_vars %in% colnames(dat))]))
        }

        # make a data.frame to predict for
        nd <- dat[dat$ddfobj == i, ]#[, df_vars, drop=FALSE]
        nd$distance <- 0

        this_ddf$method <- "2DDS"
        if(this_ddf$method == "io"){
          nd <- rbind(nd, nd)
          nd$observer <- c(rep(1, nrow(nd)/2), rep(2, nrow(nd)/2))
          dat[dat$ddfobj == i, ]$p <- predict(this_ddf, newdata=nd)$fitted
        }else if(this_ddf$method == "trial"){
          nd$observer <- 1
          dat[dat$ddfobj == i, ]$p <- predict(this_ddf, newdata=nd)$fitted
        }else{
          dat[dat$ddfobj == i, ]$p <- predict(this_ddf, newdata=nd)$fitted
        }
      }else{
        stop("Only \"ds\", \"io\" and \"trial\" models are supported!")
      }
    } # end loop over detection functions
  }

  # check that none of the Effort values are zero
  if(any(dat[, seglength.name]==0)){
    stop(paste0("Effort values for segments: ",
                paste(which(dat[, seglength.name]==0), collapse=", "),
                " are 0."))
  }

  # correct segment area units
  dat$segment.area <- dat$segment.area*convert.units

  # calculate the offset
  #   area we just calculate the area
  #   effective area multiply by p (and availability)
  #   when density is response, offset should be 1 (and is ignored anyway)
  dat$off.set <- switch(off.set,
                        eff.area = dat$segment.area*dat$p*dat$availability,
                        area     = dat$segment.area,
                        none     = 1)

  # calculate the density (count/area)
  if(response == "density.est"){
    dat[, response] <- dat[, response]/(dat$segment.area)
  }


  # Set offset as log (or whatever link is) of area or effective area
  # dat$off.set <- family$linkfun(dat$off.set)
  dat$off.set <- log(dat$off.set)

  # return(dat)
# }
```



```{r}
# dsm_temp <- 
# function (formula, ddf.obj, segment.data, observation.data, engine = "gam", 
#     convert.units = 1, family = quasipoisson(link = "log"), group = FALSE, 
#     control = list(keepData = TRUE), availability = 1, segment.area = NULL, 
#     weights = NULL, method = "REML", ...) {
#     stopifnot(engine %in% c("gam", "bam", "glm", "gamm"))
#     if (is.null(ddf.obj)) {
#         stop("NULL detection functions no longer supported, see ?dummy_ddf")
#     }
#     if (all(class(ddf.obj) != "list")) {
#         if (all(class(ddf.obj) == "dsmodel")) {
#             ddf.obj <- ddf.obj$ddf
#         }
#     } else {
#         if (length(ddf.obj) == 1) {
#             ddf.obj <- ddf.obj[[1]]
#         }
#         for (i in seq_along(ddf.obj)) {
#             if (all(class(ddf.obj[[i]]) == "dsmodel")) {
#                 ddf.obj[[i]] <- ddf.obj[[i]]$ddf
#             }
#         }
#     }
    response <- as.character(formula)[2]
    if (response %in% c("presence", "D", "density", "Dhat", "N", 
        "Nhat", "n")) {
        stop(paste("Response", response, "is deprecated, see ?dsm for details."))
    }
    possible.responses <- c("density.est", "count", "abundance.est")
    if (!(response %in% possible.responses)) {
        stop(paste("Model must be one of:", paste(possible.responses, 
            collapse = ", ")))
    }
    check.cols(ddf.obj, segment.data, observation.data, segment.area)
    # dat <- make.data_vlm(response, ddf.obj, segment.data, observation.data, 
    #     group, convert.units, availability, segment.area, family)
    dat <- dat
    
    if (!(response %in% c("density.est"))) {
        formula <- as.formula(paste(c(as.character(formula)[c(2, 
            1, 3)], "+ offset(off.set)"), collapse = ""))
    } else {
        if (is.null(weights)) {
            weights <- dat$segment.area
        } else if (length(weights) == 1) {
            weights <- rep(weights, nrow(dat))
        }
    }
    if (engine == "gamm" && dsm_env$old_mgcv) {
        message("You are using mgcv version < 1.7-24, please update to at least 1.7-24 to avoid fitting problems.")
    }
    
    if (engine %in% c("glm", "gamm")) {
        control$keepData <- NULL
    }
    args <- list(formula = abundance.est ~ s(x, y) + offset(off.set),
                 family = tw(), data = dat, 
                 weights = NULL, control = list(keepData = TRUE), method = method)
    if (engine == "glm") {
        args$method <- NULL
    }
    fit <- withCallingHandlers(do.call(engine, args), warning = "matrixnotposdef.handler")
    # if ("knots" %in% names(match.call())) {
    #     fit$knots <- get(as.character(match.call()$knots))
    # }
    # if (engine == "gamm") {
    #     fit$gam$ddf <- ddf.obj
    #     fit$gam$data <- dat
    #     fit$gam$gamm.call.list <- list(formula = formula, family = family, 
    #         data = dat, control = control)
    # } else {
    #     fit$ddf <- ddf.obj
    # }
    # class(fit) <- c("dsm", class(fit))
#     return(fit)
# }
summary(fit)
```

```{r}
# dsm.xy <- dsm_temp(abundance.est~s(x,y), ddf.obj=fitVU, unique(segdata), obsdata, method="REML")
# summary(dsm.xy)
```


