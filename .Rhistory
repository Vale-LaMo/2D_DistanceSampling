data.frame(component, CV)
stats <- list(dim(data_trunc)[1],
paste(min(data_trunc$perp_dist)," - ",max(data_trunc$perp_dist)),
paste(min(data_trunc$forw_dist)," - ",max(data_trunc$forw_dist)),
paste(params$h.function,"/",params$pi.function),
fitVU$AIC,
dim(res)[1],
sum(res$transect_length),
surveyed_area)
names(stats) <- c("Number of oservations", "Perpendicular distance range (m)",
"Forward distance range (m)", "Model",
"AIC", "Number of transects",
"Effort (km)", "Surveyed area (km2)")
as.data.frame(do.call(rbind, stats)) -> statistics
colnames(statistics) <- NULL
statistics
stats_df_groups$NhatLower*mean(data_clustersize$cluster_size) -> ind_min
stats_df_groups$NhatUpper*mean(data_clustersize$cluster_size) -> ind_max
# rows = c("Average p", "N groups", "N individuals")
Estimate = c(stats_df_groups$phat, stats_df_groups$Nhat, abund_survey_individuals[[1]])
Lower = c(stats_df_groups$lower.bound, stats_df_groups$NhatLower, ind_min)
Upper = c(stats_df_groups$upper.bound, stats_df_groups$NhatUpper, ind_max)
data.frame(Estimate,Lower,Upper) -> results
row.names(results) <- c("Average p", "N groups", "N individuals")
results
knit_with_parameters("~/Documents/GitHub/2D_DistanceSampling/00_intro_duikers_20231024.Rmd")
knit_with_parameters("~/Documents/GitHub/2D_DistanceSampling/00_intro_duikers_20231024.Rmd")
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
par(mfrow = c(1,2))
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist_perc*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = paste("output/data_trunc_", params$species_name,".RData", sep = ""), compress = FALSE)
par(mfrow = c(1,2))
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
# ystart = max(data_trunc$forw_dist) # change this to the desired truncation distance if necessary, e.g.
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = params$h.function # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = params$pi.function # perpendicular distance function used
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
# tabVU # the CIs for the average p and the N of groups are generated by bootstrap
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = paste("output/fitVU_", params$species_name, ".RData", sep = ""), compress = FALSE)
save(FIT, file = paste("output/FIT_", params$species_name, ".RData", sep = ""), compress = FALSE)
# tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# see https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# the original plotfit.x function has been modified to customize the colors
plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100);rug(x[x<=w])
fName = "h1"
# GoF for perpendicular distances
GoFx(fitVU,plot=TRUE)$pvals
# GoF for forward distances
GoFy_vlm(fitVU,plot=TRUE)$pvals
# plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
# plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,xmax=199)
(LT2D::phatModels(modList = FIT[which.min(dev)], # same as fitVU
n=length(na.omit(data_trunc$cluster_size))) -> stats_df_groups)
length(na.omit(data_trunc$cluster_size))/(phatInterval(fitVU))[1] -> no_groups
names(no_groups) <- "no_groups"
data %>%
mutate(transetto = factor(transect)) %>%
dplyr::group_by(transetto) %>%
dplyr::summarise(no_groups_transect = sum(detected),
transect_length = mean(transect_length)) %>%
mutate(encounter_rate = no_groups_transect/transect_length) -> res
# res
(2*(w/1000)*sum(res$transect_length)) -> surveyed_area # here, the truncation distance is divided by 1000, to express the density in km2
(no_groups/surveyed_area) -> dens_groups_km2
names(dens_groups_km2) <- "dens_groups_km2"
cbind(no_groups, dens_groups_km2)
data_clustersize <-
data %>%
filter(detected != 0,
perp_dist != "NA",
forw_dist != "NA",
perp_dist <= w,
forw_dist <= ystart)
data_clustersize$forw_dist <- abs(data_clustersize$forw_dist)
print("Cluster size base stats:")
summary(data_clustersize$cluster_size)
print("Cluster size standard deviation:")
sd(data_clustersize$cluster_size)
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals # estimated abundance, individuals
data.frame(abund_survey_individuals[1],abund_survey_individuals/surveyed_area) -> df
names(df) <- c("no_individuals","dens_individuals_km2")
df
cv_encounterrate <- (sd(res$encounter_rate)/mean(res$encounter_rate))
cv_detfunc <- (phatInterval(fitVU)[2])
cv_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))
cv_tot <- sqrt(cv_detfunc^2 + cv_clustersize^2 + cv_encounterrate^2)
component = c("Encounter rate", "Cluster size", "Detection function", "Abundance")
CV = c(cv_encounterrate, cv_clustersize, cv_detfunc[[1]], cv_tot[[1]])
data.frame(component, CV)
stats <- list(dim(data_trunc)[1],
paste(min(data_trunc$perp_dist)," - ",max(data_trunc$perp_dist)),
paste(min(data_trunc$forw_dist)," - ",max(data_trunc$forw_dist)),
paste(params$h.function,"/",params$pi.function),
fitVU$AIC,
dim(res)[1],
sum(res$transect_length),
surveyed_area)
names(stats) <- c("Number of oservations", "Perpendicular distance range (m)",
"Forward distance range (m)", "Model",
"AIC", "Number of transects",
"Effort (km)", "Surveyed area (km2)")
as.data.frame(do.call(rbind, stats)) -> statistics
colnames(statistics) <- NULL
statistics
stats_df_groups$NhatLower*mean(data_clustersize$cluster_size) -> ind_min
stats_df_groups$NhatUpper*mean(data_clustersize$cluster_size) -> ind_max
# rows = c("Average p", "N groups", "N individuals")
Estimate = c(stats_df_groups$phat, stats_df_groups$Nhat, abund_survey_individuals[[1]])
Lower = c(stats_df_groups$lower.bound, stats_df_groups$NhatLower, ind_min)
Upper = c(stats_df_groups$upper.bound, stats_df_groups$NhatUpper, ind_max)
data.frame(Estimate,Lower,Upper) -> results
row.names(results) <- c("Average p", "N groups", "N individuals")
results
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
par(mfrow = c(1,2))
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist_perc*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = paste("output/data_trunc_", params$species_name,".RData", sep = ""), compress = FALSE)
par(mfrow = c(1,2))
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
# ystart = max(data_trunc$forw_dist) # change this to the desired truncation distance if necessary, e.g.
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = params$h.function # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = params$pi.function # perpendicular distance function used
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
# tabVU # the CIs for the average p and the N of groups are generated by bootstrap
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = paste("output/fitVU_", params$species_name, ".RData", sep = ""), compress = FALSE)
save(FIT, file = paste("output/FIT_", params$species_name, ".RData", sep = ""), compress = FALSE)
# tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# see https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# the original plotfit.x function has been modified to customize the colors
plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100);rug(x[x<=w])
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
par(mfrow = c(1,2))
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist_perc*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = paste("output/data_trunc_", params$species_name,".RData", sep = ""), compress = FALSE)
par(mfrow = c(1,2))
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
# ystart = max(data_trunc$forw_dist) # change this to the desired truncation distance if necessary, e.g.
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = params$h.function # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = params$pi.function # perpendicular distance function used
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
# tabVU # the CIs for the average p and the N of groups are generated by bootstrap
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = paste("output/fitVU_", params$species_name, ".RData", sep = ""), compress = FALSE)
save(FIT, file = paste("output/FIT_", params$species_name, ".RData", sep = ""), compress = FALSE)
# tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# see https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# the original plotfit.x function has been modified to customize the colors
plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100);rug(x[x<=w])
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
segdata <- read_excel("data/segments400.xlsx",
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
segdata <- read_excel("data/segments400.xlsx",
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# please note that data_trunc comes from the previous 2D distance sampling analysis
load("output/data_trunc.RData")
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel("data/grid400.xlsx",
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 6)))
preddata %>%
mutate(area = 400*400) -> preddata
head(preddata)
# dsm.xy.pred <- predict.gam(fit,
#                        newdata = preddata)#,
#                        # off.set = preddata$area)
# sum(dsm.xy.pred) # numero dei gruppi
