## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
summary.dsm.var_vale(object = dsm.var.subset, detfunc = fitVU)
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_vlm(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$convertion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance)*2,
family = tw())
dat
mod1<-dsm_vale(abundance.est ~ s(x,y), fake.ddf,
segment.data, observation.data, dat = dat,
convert.units = params$convertion_km_m, group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
sum(mod1.pred)
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
summary.dsm.var_vale(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
# plot CV
# pCV <- ggplot(pp) +
#   geom_tile(aes(x=x, y=y, fill=prediction.CV, width=100, height=100)) +
#   labs(fill="CV") +
#   theme_minimal() +
#   coord_equal()
# print(pCV)
# plot SD
pSD <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=prediction.stdev, width=400, height=400)) +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pSD)
pDens <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/0.160000, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="density") +
theme_minimal() +
coord_equal()
print(pDens)
## ---- save abundance map for GIS ----
# write.csv(pp,"DSMresults2015_grigio.csv")
# write.csv(pp.uncertainty,"results/2020-02-14-DSMresults2015_grigio.csv")
write.csv(pp,"output/2023-10-27-DSMresults_impala.csv")
# write.csv(pp.uncertainty_pp,"results/2020-07-08-DSMresults2015_grigio_pp.csv") # per paper proprietÃ  private
# write.csv(pp_pp,"results/2020-02-14-DSMresults2015_grigio_pp.csv")
pp.uncertainty <- read.csv("output/2023-10-27-DSMresults_impala.csv")
sum(pp.uncertainty$Nhat)
# Here we define a convenience function to generate an appropriate data structure for ggplot2 to plot:
# given the argument fill (the covariate vector to use as the fill) and a name,
# return a geom_polygon object
# fill must be in the same order as the polygon data
grid_plot_obj <- function(fill, name, sp){
# what was the data supplied?
names(fill) <- NULL
row.names(fill) <- NULL
data <- data.frame(fill)
names(data) <- name
spdf <- SpatialPolygonsDataFrame(sp, data)
spdf@data$id <- rownames(spdf@data)
spdf.points <- fortify(spdf, region="id")
spdf.df <- join(spdf.points, spdf@data, by="id")
# seems to store the x/y even when projected as labelled as
# "long" and "lat"
spdf.df$x <- spdf.df$long
spdf.df$y <- spdf.df$lat
geom_polygon(aes_string(x="x",y="y",fill=name, group="group"), data=spdf.df)
}
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_vlm(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$convertion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance)*2,
family = tw())
dat
mod1<-dsm_vale(abundance.est ~ s(x,y), fake.ddf,
segment.data, observation.data, dat = dat,
convert.units = params$convertion_km_m, group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
sum(mod1.pred)
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
summary.dsm.var_vale(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
# plot SD
pSD <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=prediction.stdev, width=400, height=400)) +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pSD)
# pDens <- ggplot(pp) +
#   geom_tile(aes(x=x, y=y, fill=Nhat/0.160000, width=400, height=400)) +
#   scale_fill_distiller(palette = "YlGn", direction=2) +
#   #                      values = c(seq(0, 60, 60))) +
#   # scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#   #                      name = "log10(Similarity)") +
#   labs(fill="density") +
#   theme_minimal() +
#   coord_equal()
# print(pDens)
## ---- save abundance map for GIS ----
write.csv(pp,paste("output/DSMresults_", params$species_name,
".csv", sep = ""))
# pp.uncertainty <- read.csv(paste("output/DSMresults_",
#                                  params$species_name,
#                                  ".csv", sep = ""))
# sum(pp.uncertainty$Nhat)
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
library(rgdal)
library(plyr)
library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_vlm(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$convertion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance)*2,
family = tw())
dat
mod1<-dsm_vale(abundance.est ~ s(x,y), fake.ddf,
segment.data, observation.data, dat = dat,
convert.units = params$convertion_km_m, group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
sum(mod1.pred)
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
summary.dsm.var_vale(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
# plot SD
pSD <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=prediction.stdev, width=400, height=400)) +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pSD)
# pDens <- ggplot(pp) +
#   geom_tile(aes(x=x, y=y, fill=Nhat/0.160000, width=400, height=400)) +
#   scale_fill_distiller(palette = "YlGn", direction=2) +
#   #                      values = c(seq(0, 60, 60))) +
#   # scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#   #                      name = "log10(Similarity)") +
#   labs(fill="density") +
#   theme_minimal() +
#   coord_equal()
# print(pDens)
## ---- save abundance map for GIS ----
write.csv(pp,paste("output/DSMresults_", params$species_name,
".csv", sep = ""))
# pp.uncertainty <- read.csv(paste("output/DSMresults_",
#                                  params$species_name,
#                                  ".csv", sep = ""))
# sum(pp.uncertainty$Nhat)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
summary.dsm.var_vale(object = dsm.var.subset, detfunc = fitVU)
