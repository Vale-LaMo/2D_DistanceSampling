ind_min <- D_min*surveyed_area
ind_max <- D_max*surveyed_area
# based on Buckland et al. 1993, Ch. 3, pp. 88-89
# rows = c("Average p", "N groups", "N individuals")
Estimate = c(stats_df_groups$phat,
stats_df_groups$Nhat,
abund_survey_individuals[[1]])
Lower = c(stats_df_groups$lower.bound, stats_df_groups$NhatLower, ind_min)
Upper = c(stats_df_groups$upper.bound, stats_df_groups$NhatUpper, ind_max)
data.frame(Estimate = round(Estimate,3),
Lower = round(Lower,3),
Upper = round(Upper,3)) -> results
row.names(results) <- c("Average p", "N groups", "N individuals")
results
data %>%
mutate(Region.Label = "Study area",
Area = surveyed_area) %>%
dplyr::rename(#Area = area,
Sample.Label = transect,
Effort = transect_length,
distance = perp_dist,
size = cluster_size) -> data_cds
head(data_cds)
conversion.factor <- convert_units("meter", "kilometer", "Square kilometer")
cds.hr <- ds(data=data_cds, key="hr", adjustment=NULL,
convert_units=conversion.factor,
dht_group = FALSE, # group size must be taken into account
truncation = threshold)
plot(cds.hr,main="Hazard rate model, Conventional Distance Sampling", xlab = "Distance (m)")
# summary(cds.hr)
Estimate = c(cds.hr$dht$individuals$N$Estimate, abund_survey_individuals[[1]])
se = c(cds.hr$dht$individuals$N$se, sd[4])
cv = c(cds.hr$dht$individuals$N$cv, CV[4])
Lower = c(cds.hr$dht$individuals$N$lcl, ind_min)
Upper = c(cds.hr$dht$individuals$N$ucl, ind_max)
data.frame(Estimate = round(Estimate,3),
se = round(se, 3),
cv = round(cv, 3),
Lower = round(Lower,3),
Upper = round(Upper,3)) -> comparison
row.names(comparison) <- c("CDS", "2D-DS")
comparison
library(ggplot2)
ggplot(comparison, aes(x=row.names(comparison), y=Estimate)) +
geom_bar(position=position_dodge(.9), colour="black", stat="identity", fill = "white") +
geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=Lower, ymax=Upper)) +
xlab("") + ylab("Estimated N")
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
# library(rgdal)
library(plyr)
# library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_mod.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
# orignal file name: impala_segmenti_vlm_NEW.xlsx/imapla_segementi_vlm_NEW.xlsx
#"data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
segdata$Effort <- segdata$Effort # effort now expressed in m
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
obsdata$Effort <- obsdata$Effort # effort now expressed in m
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
preddata$area <- preddata$area
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_mod(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$conversion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance),#*2,
family = tw())
dat
mod1<-dsm_mod(abundance.est ~ s(x,y,k=4), fake.ddf,
segment.data, observation.data, dat = dat,
# convert.units = 1,
convert.units = params$conversion_km_m,
group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# mod1.pred <- predict(mod1, preddata, preddata$area*1000)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
# sum(mod1.pred)
limit <- summary(mod1.pred)[5]*1.5
sum(mod1.pred[mod1.pred<limit])
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset, #seglen.varname = "Effort",
type.pred = "response")
# summary(dsm.var.subset)
fName = "h.RE"
summary.dsm.var_mod(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
# pNhat <- ggplot(pp) +
#   geom_tile(aes(x=x, y=y, fill=Nhat,
#                 width=1/params$conversion_km_m,
#                 height=1/params$conversion_km_m)) +
#   scale_fill_distiller(palette = "YlGn", direction=2,
#                        breaks = seq(min(pp$Nhat),max(pp$Nhat), length.out = 4),
#                        labels = round((seq(min(pp$Nhat),
#                                            max(pp$Nhat),
#                                            length.out = 4)/(preddata$area[1]/1000000)),0))+
#   #                      values = c(seq(0, 60, 60))) +
#   # scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#   #                      name = "log10(Similarity)") +
#   labs(fill="Nhat") +
#   theme_minimal() +
#   coord_equal()
# print(pNhat)
logo_path <- paste("logos/", params$species_name, "_logo.png",sep = "")
logo <- readPNG(logo_path)
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
# library(rgdal)
library(plyr)
# library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_mod.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
segdata$Effort <- segdata$Effort # effort now expressed in m
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
obsdata$Effort <- obsdata$Effort # effort now expressed in m
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
preddata$area <- preddata$area
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_mod(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$conversion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance),#*2,
family = tw())
dat
mod1<-dsm_mod(abundance.est ~ s(x,y,k=4), fake.ddf,
segment.data, observation.data, dat = dat,
# convert.units = 1,
convert.units = params$conversion_km_m,
group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
# sum(mod1.pred)
limit <- summary(mod1.pred)[5]*1.5
sum(mod1.pred[mod1.pred<limit])
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset,
type.pred = "response")
# summary(dsm.var.subset)
fName = "h.RE"
summary.dsm.var_mod(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/(preddata$area[1]/1000000),
width=(1/params$conversion_km_m)*tile_factor,
height=(1/params$conversion_km_m)*tile_factor)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
# scale_fill_distiller(palette = "YlGn", direction=2,
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pNhat)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/(preddata$area[1]/1000000),
width=(1/params$conversion_km_m),
height=(1/params$conversion_km_m))) +
scale_fill_distiller(palette = "YlGn", direction=2) +
# scale_fill_distiller(palette = "YlGn", direction=2,
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pNhat)
# plot SD
pSD <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=prediction.stdev/(preddata$area[1]/1000000),
width=1/params$conversion_km_m,
height=1/params$conversion_km_m)) +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pSD)
## ---- save abundance map for GIS ----
write.csv(pp,paste("output/DSMresults_", params$species_name,
".csv", sep = ""))
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
library(distill)
# library(rgdal)
library(plyr)
# library(maptools)
library(tweedie)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_mod.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/dsm_custom_functions.R")
#### Load dataset
segdata <- read_excel(paste("data/",params$segdata_file,sep=""),
col_types = c(rep("text", 2),
rep("numeric", 3)))
head(segdata)
segdata$Effort <- segdata$Effort # effort now expressed in m
obsdata <- read_excel(paste("data/",params$obsdata_file,sep=""),
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
obsdata$Effort <- obsdata$Effort # effort now expressed in m
# please note that data_trunc comes from the previous 2D distance sampling analysis
load(paste("output/data_trunc_",params$species_name,".RData",sep = ""))
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
dplyr::rename(size = cluster_size, distance = perp_dist) -> obsdata
# include a column to identify the detection function object: here, we only have one detection function
# so the ddfobj colum has a fixed value of 1 and it is added to both the segments and the observation datasets
obsdata %>%
mutate(ddfobj = 1) -> obsdata
segdata %>%
mutate(ddfobj = 1) -> segdata
head(obsdata)
#### Load dataset
preddata <- read_excel(paste("data/", params$preddata_file, sep = ""),
col_types = rep("numeric", 4))
head(preddata)
preddata$area <- preddata$area
load(paste("output/fitVU_", params$species_name, ".RData", sep = ""))
est = fitVU
Nhat.yx=bias=NULL
b=est$b; hr=match.fun(est$hr); ystart=est$ystart; pi.x=match.fun(est$pi.x)
logphi=est$logphi; w=est$w
x = obsdata$distance
f.x=p.x.std=adbnTRUE=0
arrange(obsdata, distance) %>%
dplyr::select(object, distance) %>%
na.omit() -> gridx.df
p.xpifit=p.pi.x(gridx.df$distance,b,hr,ystart,pi.x,logphi,w)
mufit=integrate(f=p.pi.x,lower=0,upper=w,b=b,hr=hr
,ystart=ystart,pi.x=pi.x,logphi=logphi,w=w)$value # phat media dei gruppi
f.xfit=p.xpifit/mufit
p.xfit=px(gridx.df$distance,b,hr,ystart,nint=nint)
ptot=integrate(f=px,lower=0,upper=w,b=b,hr=hr,ystart=ystart)$value
p.xfit.std=p.xfit/ptot
adbn=pi.x(gridx.df$distance,logphi,w)
bind_cols(p=p.xfit.std, gridx.df) -> fitted.p.df
bind_cols(p=p.xfit, gridx.df) -> fitted.p.df
fitted.p.df
# if we didn't use ds()...
# probs <- hr.model$ddf$fitted
# object.ids <- names(hr.model$ddf$fitted)
probs <- fitted.p.df$p
object.ids <- fitted.p.df$object
fake.ddf <- list()
fake.ddf$meta.data <- list()
# fake.ddf$meta.data$width <- max(mexdolphins$distdata$distance)
fake.ddf$meta.data$width <- max(fitted.p.df$distance)
fake.ddf$meta.data$left <- 0
fake.ddf$fitted <- probs
names(fake.ddf$fitted) <- object.ids
fake.ddf
dat <- make.data_mod(response = "abundance.est", ddfobject = fitVU,
segdata, obsdata, group = FALSE,
convert.units = params$conversion_km_m,
availability = 1,
segment.area = segdata$Effort*max(fitted.p.df$distance)*2,
family = tw())
dat
mod1<-dsm_mod(abundance.est ~ s(x,y,k=4), fake.ddf,
segment.data, observation.data, dat = dat,
# convert.units = 1,
convert.units = params$conversion_km_m,
group = FALSE)
summary(mod1)
# predict over a grid
mod1.pred <- predict(mod1, preddata, preddata$area)
# calculate the predicted abundance over the grid
print("Predicted abundance (no. individuals) over the grid:")
# sum(mod1.pred)
limit <- summary(mod1.pred)[5]*1.5
sum(mod1.pred[mod1.pred<limit])
# plot the smooth
plot(mod1)
## --- Variance estimation for the chosen model ----
preddata.varprop.subset <- split(preddata, 1:nrow(preddata))
offset.varprop.subset <- as.list(rep(preddata$area[1],nrow(preddata)))
dsm.var.subset <- dsm_var_gam(dsm.obj=mod1, pred.data=preddata.varprop.subset,
off.set = offset.varprop.subset,
type.pred = "response")
# summary(dsm.var.subset)
fName = "h.RE"
summary.dsm.var_mod(object = dsm.var.subset, detfunc = fitVU)
## ---- prediction and plot Nhat and uncertainty ----
prediction.Nhat <- unlist(dsm.var.subset$pred)
prediction.CV <- sqrt(dsm.var.subset$pred.var)/unlist(dsm.var.subset$pred)
prediction.stdev <- sqrt(dsm.var.subset$pred.var)
pp <- mutate(as.data.frame(preddata), Nhat = prediction.Nhat)
pp.uncertainty <- mutate(pp, CV = prediction.CV, stdev = prediction.stdev)
# plot Nhat
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/(preddata$area[1]/1000000),
width=(1/params$conversion_km_m),
height=(1/params$conversion_km_m))) +
scale_fill_distiller(palette = "YlGn", direction=2) +
# scale_fill_distiller(palette = "YlGn", direction=2,
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pNhat)
# plot SD
pSD <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=prediction.stdev/(preddata$area[1]/1000000),
width=1/params$conversion_km_m,
height=1/params$conversion_km_m)) +
labs(fill="SD") +
theme_minimal() +
coord_equal()
print(pSD)
## ---- save abundance map for GIS ----
write.csv(pp,paste("output/DSMresults_", params$species_name,
".csv", sep = ""))
