geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
# scale_fill_distiller(palette = "YlGn", direction=2,
#                      values = c(0, 0.01, seq(0.05, 1, 0.05)))
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(0, seq(1, 20, 20), 40, 60))
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
seq(1, 20, 10)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(0, seq(1, 20, 10), 40, seq(41, 60, 19)) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(0, seq(1, 20, 10), 40, seq(41, 60, 19)) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(0, seq(1, 20, 10), 40, seq(41, 60, 19))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(0, 5, 10, 15, 20, 40, 60)) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(seq(0, 60, 10))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
seq(0, 60, 10)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2,
values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
# scale_fill_distiller(palette = "YlGn", direction=2,
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
pNhat <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="Nhat") +
theme_minimal() +
coord_equal()
print(pNhat)
print(pNhat)
print(pNhat)
pDens <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/16000, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="density") +
theme_minimal() +
coord_equal()
print(pDens)
pDens <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/0.016000, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="density") +
theme_minimal() +
coord_equal()
print(pDens)
400*400
pDens <- ggplot(pp) +
geom_tile(aes(x=x, y=y, fill=Nhat/0.160000, width=400, height=400)) +
scale_fill_distiller(palette = "YlGn", direction=2) +
#                      values = c(seq(0, 60, 60))) +
# scale_fill_distiller(palette = "YlGn", direction=2, trans = "log10",
#                      name = "log10(Similarity)") +
labs(fill="density") +
theme_minimal() +
coord_equal()
print(pDens)
prediction.CV
prediction.stdev
head(pp.uncertainty)
summary(pp.uncertainty)
dsm.xy.var <- dsm_var_prop(mod1, pred.data=preddata.var,
off.set=preddata$area)
mod_count<-dsm_vale(count ~ s(x,y), fake.ddf,
segment.data, observation.data, dat = dat,
convert.units = 1/1000, group = FALSE)
dsm_vale
dsm.xy.var <- dsm_varprop(mod1, pred.data=preddata.var,
off.set=preddata$area)
dsm.xy.var <- dsm_varprop(mod1, newdata=preddata.var)
dsm.xy.var <- dsm_varprop(mod1, newdata=preddata)
summary(dsm.xy.var) # questo non funziona
dsm.xy.var <- dsm_var_gam(mod1, pred.data=preddata.var,
off.set=preddata$area)
summary(dsm.xy.var) # questo non funziona
names(dsm.xy.var)
dsm.xy.var$pred.var
dsm.xy.var
names(dsm.xy.var)
names(mod1)
fake.dds
fake.ddf
names(fake.ddf)
fitVU
mod1
summary(mod1)
names(mod1)
mod1$ddf
summary(fitVU)
names(fitVU)
summary(fitVU$pi.x())
summary(fitVU$pi.x
)
fitVU$pi.x
fitVU$SE
fitVU$hr
fitVU$SE
# cv2_detfunc <- (phatInterval(fitVU)[2])
cvp.sq <- (phatInterval(fitVU)[2])
phatInterval(fitVU)
cv2_detfunc <- (phatInterval(fitVU)[2])^2
# sinfo$average.p.se <- ddf.summary$average.p.se
# cvp.sq <- (ddf.summary$average.p.se/
#                  ddf.summary$average.p)^2
# this_cvp.sq <- (ddf.summary$average.p.se/
#                           ddf.summary$average.p)^2
cvp.sq <- cv2_detfunc
this_cvp.sq <- cv2_detfunc
summary(dsm.xy.var) # questo non funziona
summary.ds.var.vale(dsm.xy.var) # questo non funziona
summary.dsm.var.vale(dsm.xy.var) # questo non funziona
source("functions/summary.dsm.var.vale.R")
summary.dsm.var.vale(dsm.xy.var) # questo non funziona
abund_survey_individuals
# calculate the predicted abundance over the grid
sum(mod1.pred)
dim(preddata)
9429.353/(400*400)
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
cbind(dens_gruppi_km2, dens_ind_km2)
9429.353/6552
SE = (27505.77 - 3232.511) /3.92
SE
SE/9429.353
abund_survey_individuals
dim(preddata)
9429/(dim(preddata[1]))
(dim(preddata[1]))
9429/(dim(preddata))
head(preddata)
dim(preddata)
(dim(preddata))[1]
9429/((dim(preddata))[1]*400*400)
9429/((dim(preddata))[1])
9429/((dim(preddata))[1])
1.4/0.16
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = "output/data_trunc.RData", compress = FALSE)
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = "output/data_trunc.RData", compress = FALSE)
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
paste("output/data_trunc_",params$species,".RData",sep="")
paste("output/data_trunc_",params$species,".RData",sep="")
knit_with_parameters("C:/Users/valen/git/2D_DistanceSampling/00_intro_duikers_def.Rmd")
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
col_types = c(rep("numeric", 8),
"date",
"text", "text"))
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
save(data_trunc, file = paste("output/data_trunc_",params$species,".RData",sep=""), compress = FALSE)
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = paste("output/fitVU_",params$species,".RData",sep=""), compress = FALSE)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = paste("output/fitVU_",params$species,".RData",sep=""), compress = FALSE)
tryCatch.W.E(plotfit.x(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
fName = "h1"
GoFx(fitVU,plot=TRUE)$pvals
plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
GoFy_vlm(fitVU,plot=TRUE)$pvals # brillantemente risolto
plotfit.smoothfy(fitVU,xmax=199)
#EHSW:
# phatInterval(fitVU) %>%
#   dplyr::select(-interval)
LT2D::phatModels(modList = FIT[1], n=length(data$cluster_size))
length(data$cluster_size)/(phatInterval(fitVU))[1] -> no_groups
names(no_groups) <- "no_groups"
(no_groups/(2*(w/1000)*sum(data$transect_length))) -> dens_groups_km2
names(dens_groups_km2) <- "dens_groups_km2"
cbind(no_groups, dens_groups_km2)
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
# as.data.frame(phatInterval(fitVU)*w) %>%
#   dplyr::select(-interval) %>%
#   dplyr::rename(Nhat = phat,
#                 CV.Nhat = CV.phat)# riassegnare i nomi alla tabella, eliminando interval restano: Nhat dei gruppi nella regione indagata (w), CV del numero di gruppi e limiti dell'intervallo
# p(0):
# p0.n=tryCatch.W.E(1-Sy(0,0,ystart,fitVU$b,h1));p0.n
data_clustersize <-
data %>%
filter(detected != 0,
perp_dist != "NA",
forw_dist != "NA",
perp_dist <= w,
forw_dist <= ystart)
data_clustersize$forw_dist <- abs(data_clustersize$forw_dist)
# mean(data_clustersize$cluster_size)
summary(data_clustersize$cluster_size)
print("Cluster size standard deviation:")
sd(data_clustersize$cluster_size)
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
cv2_detfunc <- (phatInterval(fitVU)[2])^2
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
data %>%
mutate(transetto = factor(transect)) %>%
dplyr::group_by(transect) %>%
dplyr::summarise(no_groups_transect = sum(detected),
transect_length = mean(transect_length)) %>%
mutate(encounter_rate = no_groups_transect/transect_length) -> res
res
res$no_groups_transect
cv2_transetti <- (sd(res$encounter_rate)/mean(res$encounter_rate))^2
(cv_tot <- sqrt(cv2_detfunc + cv2_clustersize + cv2_transetti))
data_transects <- read_excel("data/duiker_vlm.xlsx",  # controllare!!
sheet="template_dataset",
col_types = c(rep("numeric", 3),
"date",
"text", "text",
rep("numeric", 5)))
data_transects <- read_excel("data/duiker_vlm.xlsx",  # controllare!!
# sheet="template_dataset",
col_types = c(rep("numeric", 3),
"date",
"text", "text",
rep("numeric", 5)))
data_transects %>%
distinct(transect, transect_length) -> data_transects_unique
### Population density
transect.lengths = data_transects_unique$transect_length
sum(transect.lengths)*2*w/1000 # area indagata
phatInterval(fitVU)*w -> abund_survey # num gruppi, i nomi delle colonne sono da modificare
abund_survey[1]/sum(transect.lengths)/(fitVU$w/1000) -> dens_gruppi_km2
names(dens_gruppi_km2) <- "no_gruppi_km2"
abund_survey_individuals[1]/sum(transect.lengths)/(fitVU$w/1000) -> dens_ind_km2 # individui
names(dens_ind_km2) <- "no_ind_km2"
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
cbind(dens_gruppi_km2, dens_ind_km2)
tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
