no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
abund_survey_individuals
phatInterval(fitVU)
w
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
cv2_clustersize
(sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))
sd(data_clustersize$cluster_size)
phatInterval(fitVU))[2]
phatInterval(fitVU)
phatInterval(fitVU)[2]
data %>%
na.rm()
summarise(n())
data %>%
group_by(transect) %>%
summarise(n())
na.rm(data)
na.omit(data) %>%
group_by(transect) %>%
summarise(n())
na.omit(data)
data %>%
group_by(transect) %>%
summarise(sum(detected))
data %>%
group_by(transect) %>%
summarise(no_groups_transect = sum(detected)) %>%
(sd(no_groups_transect)/mean(no_groups_transect))
data %>%
group_by(transect) %>%
summarise(no_groups_transect = sum(detected)) -> res
res %>%
(sd(no_groups_transect)/mean(no_groups_transect))
data %>%
group_by(transect) %>%
summarise(no_groups_transect = sum(detected)) -> res
res
res %>%
(sd(no_groups_transect)/mean(no_groups_transect))
res %>%
(sd(res$no_groups_transect)/mean(res$no_groups_transect))
(sd(res$no_groups_transect)/mean(res$no_groups_transect))
(cv_tot <- sqrt(cv2_gruppi + cv2_clustersize + cv2_transetti))
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
cv2_detfunc <- (phatInterval(fitVU)[2])^2
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
cv2_transetti <- (sd(res$no_groups_transect)/mean(res$no_groups_transect))^2
(cv_tot <- sqrt(cv2_gruppi + cv2_clustersize + cv2_transetti))
#### Load dataset
data <- read_excel("data/impala_vlm.xlsx", sheet="template_dataset",
col_types = c(rep("numeric", 3),
"date",
"text", "text",
rep("numeric", 5)))
data %>%
filter(cluster_size < 30) -> data
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
# tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
fName = "h1"
GoFx(fitVU,plot=TRUE)$pvals
plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
GoFy_vlm(fitVU,plot=TRUE)$pvals # brillantemente risolto
plotfit.smoothfy(fitVU,xmax=199)
#EHSW:
# phatInterval(fitVU) %>%
#   dplyr::select(-interval)
LT2D::phatModels(modList = FIT[1], n=length(data$cluster_size))
length(data$cluster_size)/(phatInterval(fitVU))[1] -> no_groups
names(no_groups) <- "no_groups"
no_groups/(2*w/1000*sum(data$transect_length)) -> dens_groups_km2
names(dens_groups_km2) <- "dens_groups_km2"
cbind(no_groups, dens_groups_km2)
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
# as.data.frame(phatInterval(fitVU)*w) %>%
#   dplyr::select(-interval) %>%
#   dplyr::rename(Nhat = phat,
#                 CV.Nhat = CV.phat)# riassegnare i nomi alla tabella, eliminando interval restano: Nhat dei gruppi nella regione indagata (w), CV del numero di gruppi e limiti dell'intervallo
# p(0):
# p0.n=tryCatch.W.E(1-Sy(0,0,ystart,fitVU$b,h1));p0.n
data_clustersize <-
data %>%
filter(detected != 0,
perp_dist != "NA",
forw_dist != "NA",
perp_dist <= w,
forw_dist <= ystart)
data_clustersize$forw_dist <- abs(data_clustersize$forw_dist)
# mean(data_clustersize$cluster_size)
summary(data_clustersize$cluster_size)
print("Cluster size standard deviation:")
sd(data_clustersize$cluster_size)
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
cv2_detfunc <- (phatInterval(fitVU)[2])^2
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
data %>%
group_by(transect) %>%
summarise(no_groups_transect = sum(detected)) -> res
cv2_transetti <- (sd(res$no_groups_transect)/mean(res$no_groups_transect))^2
(cv_tot <- sqrt(cv2_gruppi + cv2_clustersize + cv2_transetti))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
data <- read_excel("data/impala_vlm.xlsx", sheet="template_dataset",
col_types = c(rep("numeric", 3),
"date",
"text", "text",
rep("numeric", 5)))
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
# tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
tryCatch.W.E(plotfit.x(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
fName = "h1"
GoFx(fitVU,plot=TRUE)$pvals
plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
GoFy_vlm(fitVU,plot=TRUE)$pvals # brillantemente risolto
plotfit.smoothfy(fitVU,xmax=199)
#EHSW:
# phatInterval(fitVU) %>%
#   dplyr::select(-interval)
LT2D::phatModels(modList = FIT[1], n=length(data$cluster_size))
install.packages(c("dsm", "Distance", "knitr", "distill", "ggplot2", "rgdal",
"maptools", "plyr", "tweedie"))
install.packages(c("dsm", "Distance", "distill", "rgdal",
"maptools", "plyr", "tweedie"))
# install.packages(c("dsm", "Distance", "distill", "rgdal",
#                    "maptools", "plyr", "tweedie"))
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
library(dsm)
library(Distance)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
data <- read_excel("data/impala_segmenti_vlm.xlsx", #sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(data)
#### Load dataset
segdata <- read_excel("data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
rep("numeric", 3))
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c(numeric,
rep("text", 2),
rep("numeric", 3)))
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c("numeric",
rep("text", 2),
rep("numeric", 3)))
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
dsm
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages()))
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
#### Load dataset
data <- read_excel("data/impala_vlm.xlsx", sheet="template_dataset",
col_types = c(rep("numeric", 3),
"date",
"text", "text",
rep("numeric", 5)))
head(data)
#### Dealing with NA and non-detections
data_clean <-
data %>%
filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
perp_dist != "NA", # we remove lines with NA distances
forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")
no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <-
data_clean %>%
filter(perp_dist <= threshold)
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
ystart = params$trunc_forw_dist_m
data_trunc <-
data_trunc %>%
filter(forw_dist <= ystart)
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE
FIT=list(); dev=NULL
for (m in 1:10) {
set.seed(params$seed_no)
pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
set.seed(params$seed_no)
tmp0 <- tryCatch.W.E (
fityx(y,x,pars[1:length.b],
hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
hessian=TRUE,corrFlag=0.7,debug=FALSE)
)
fit = NA
if(! "error" %in% class(tmp0$value)) {
fit <- tmp0$value
fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
}
FIT[[m]] = fit
if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
}
fitVU = FIT[[which.min(dev)]]
tabVU = matrix(NA,2,3)
if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
# set.seed(10)
tmp1 <- tryCatch.W.E (boot(fitVU))
if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
}
tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
tryCatch.W.E(plotfit.x(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
fName = "h1"
GoFx(fitVU,plot=TRUE)$pvals
plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
GoFy_vlm(fitVU,plot=TRUE)$pvals # brillantemente risolto
plotfit.smoothfy(fitVU,xmax=199)
#EHSW:
# phatInterval(fitVU) %>%
#   dplyr::select(-interval)
LT2D::phatModels(modList = FIT[1], n=length(data$cluster_size))
length(data$cluster_size)/(phatInterval(fitVU))[1] -> no_groups
names(no_groups) <- "no_groups"
no_groups/(2*w/1000*sum(data$transect_length)) -> dens_groups_km2
names(dens_groups_km2) <- "dens_groups_km2"
cbind(no_groups, dens_groups_km2)
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
# as.data.frame(phatInterval(fitVU)*w) %>%
#   dplyr::select(-interval) %>%
#   dplyr::rename(Nhat = phat,
#                 CV.Nhat = CV.phat)# riassegnare i nomi alla tabella, eliminando interval restano: Nhat dei gruppi nella regione indagata (w), CV del numero di gruppi e limiti dell'intervallo
# p(0):
# p0.n=tryCatch.W.E(1-Sy(0,0,ystart,fitVU$b,h1));p0.n
data_clustersize <-
data %>%
filter(detected != 0,
perp_dist != "NA",
forw_dist != "NA",
perp_dist <= w,
forw_dist <= ystart)
data_clustersize$forw_dist <- abs(data_clustersize$forw_dist)
# mean(data_clustersize$cluster_size)
summary(data_clustersize$cluster_size)
print("Cluster size standard deviation:")
sd(data_clustersize$cluster_size)
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
cv2_detfunc <- (phatInterval(fitVU)[2])^2
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
data %>%
group_by(transect) %>%
summarise(no_groups_transect = sum(detected)) -> res
cv2_transetti <- (sd(res$no_groups_transect)/mean(res$no_groups_transect))^2
(cv_tot <- sqrt(cv2_gruppi + cv2_clustersize + cv2_transetti))
class(fitVU)
fitVU
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
#### Load dataset
segdata <- read_excel("data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
#### Load dataset
segdata <- read_excel("data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
#### Load dataset
segdata <- read_excel("data/impala_segmenti_vlm.xlsx",
#sheet="template_dataset",
col_types = c(rep("text", 2),
rep("numeric", 3),
"text",
rep("numeric", 5)))
head(segdata)
obsdata <- read_excel("data/obsdata.xlsx",
#sheet="template_dataset",
col_types = c("numeric",
"text",
rep("numeric", 3)))
head(obsdata)
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
distdata <- data_trunc
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
head(distdata)
View(distdata)
names(distdata)
distdata %>%
rename(size = cluster_size,
distance = perp_dist) -> distdata
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
names(distdata)
distdata <- data_trunc
distdata %>%
rename(size = cluster_size,
distance = perp_dist) -> distdata
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
left_join(obsdata, data_trunc, by = "object")
left_join(obsdata, data_trunc, by = "object") %>%
dplyr::select(object:Effort, cluster_size, perp_dist) %>%
rename(size = cluster_size, distance = perp_dist) -> obsdata
dsm.xy <- dsm(count~s(x,y), fitVU, segdata, obsdata, method="REML")
View(fitVU)
# load data
data(book.tee.data)
region <- book.tee.data$book.tee.region
egdata <- book.tee.data$book.tee.dataframe
samples <- book.tee.data$book.tee.samples
obs <- book.tee.data$book.tee.obs
# fit a half-normal detection function
result <- ddf(dsmodel=~mcds(key="hn", formula=~1), data=egdata, method="ds",
meta.data=list(width=4))
result
names(result)
names(fitVU)
names(fitVU$hr)
(fitVU$hr)
fitVU
result$dsmodel
result$model
result$ds
dsm
dsm.xy <- dsm(count~s(x,y), ddf.obj=fitVU, segdata, obsdata, method="REML")
summary(fitVU)
View(FIT)
View(result)
