---
title: "2D distance sampling"
params:
  seed_no: 16
  trunc_perp_dist: 5
  input_file: "impala_vlm.xlsx"
output:
  html_document:
    df_print: paged
---

```{r packages, message=FALSE}
#### Load packages
library(tidyverse)
library(readxl)
library(mvtnorm)
# if(!"devtools" %in% rownames(installed.packages())) 
#   {install.packages("devtools")}
# devtools::install_github('david-borchers/LT2D')
library(LT2D)
```

```{r functions}
#### Load 2D distance functions
source("functions/com_hfunctions.R")
source("functions/com_pifunctions.R")
source("functions/com_likelihoodutilities.R")
source("functions/GoFy_vlm.R") # custom GoFy function, modified by VLM 2022-11-11
source("functions/plotfit.x.red.R") # custom function, modified by VLM 2023-08-31, to have a red line instead of a grey one
```

In distance sampling surveys, the animals might avoid both the transects in the absence of observers, and the observers themselves.
To correct for the effect of the behavioral responses of the animals to either the transects or the observers, we can estimate density and abundance using line transect survey data with both the forward and perpendicular distances to the observers (2D distance sampling), not just the perpendicular distance (R LT2D package, Borchers and Cox 2015). This analysis approach was also applied and recommended by Elenga et al. (2020).

Here, we rely on the functions from LT2D package (https://github.com/david-borchers/LT2D), as partly revised and applied in Elenga et al. (2020) (https://github.com/cbonenfant/duikers-abundance). With respect to the latter, we made additional minor changes to the code. All the code and functions used are available on https://github.com/Vale-LaMo/2D_DistanceSampling

# Detection function fitting: impala

## Data import

First of all, we need to import the data. The dataset (Excel file) should include the following columns (order matters):   

- `area`: surface of the study area, in km2
- `transect`: transect label (it could be a number or a letter)
- `transect_length`: length of the transect, in km
- `detected`: a field whose value is 1 in case of detection of a group of animals, 0 otherwise
- `object`: a progressive number to identify each record (*i.e.*, 1,2,3,4,...)
- `perp_dist`: perpendicular distance to the observer (only if the group has been detected)
- `forw_dist`: forward distance to the observer (only if the group has been detected)
- `cluster_size`: number of animals in the group (optional, only if the group has been detected)
- `obs_time`: date and time stamp (optional)
- `X_observer`: x-coord of the observer (optional)
- `Y_observer`: y-coord of the observer (optional)

All optional fields and the distance columns can have empty cells (or *NA*) in the Excel file. On the contrary, *NA*s are not admitted in the fields: `area`, `transect`, `transect_length`, `detected`, `object` (i.e., if the above order is respected, *NAs* are not admitted in the first 5 columns but can be present in the other ones). Values in the `forw_dist` column can also be negative.

*Please note that when reading the file, we specify the column types, that is why the order is important. Make sure to maintain the recommended order of the columns to avoid errors in the procedure; additional columns could of course be added, or the order changed, but then you will have to modify the `col_types` argument accordingly*

```{r data-loading}
#### Load dataset
data <- read_excel(paste("data/",params$input_file,sep=""), #sheet="template_dataset",
                   col_types = c(rep("numeric", 8),
                                 "date",
                                 "text", "text"))
```
*The previous messages simply warn us on the presence of some NAs in the columns with numeric data. We will deal with them later but please go back and check your data if you did not expect this to happen.*

The data looks as follows:
```{r data-preview}
# data$transect_length <- data$transect_length*1000
# data$area <- data$area*1000000
head(data)
```

## Data cleaning and truncation

Second, we clean the data: we remove the lines of the transects without any observation (`detected = 0`) and we also exclude records for which distances are missing.

```{r data-cleaning}
#### Dealing with NA and non-detections
data_clean <- 
  data %>% 
  filter(detected != 0, # we only include actual observations in the dataset used to fit the detection function
         perp_dist != "NA", # we remove lines with NA distances
         forw_dist != "NA")
data_clean$forw_dist <- abs(data_clean$forw_dist) # we make sure all distances are positive (see Discussion for details)
```

We now select the truncation distances. For this purpose, we produce histograms and boxplots to identify outliers.

```{r truncation-perpendicular-distances}
hist(data_clean$perp_dist, main = "", xlab = "Perpendicular distance (m)")
boxplot(data_clean$perp_dist, ylab = "Perpendicular distance (m)")

no_data <- round(params$trunc_perp_dist*length(data_clean$perp_dist)/100,0) # no. data to be deleted
threshold <- sort(data_clean$perp_dist, decreasing = TRUE)[no_data+1] # threshold
data_trunc <- 
  data_clean %>% 
  filter(perp_dist <= threshold)
save(data_trunc, file = "output/data_trunc.RData", compress = FALSE)
```

The first histogram shows we have a very long tail for perpendicular distances, and the boxplot confirms that we have potential outliers. Using a truncation distance of `r params$trunc_perp_dist`%, we remove `r no_data` records.   

We also produce the histogram and the boxplot for the forward distances:

```{r truncation-forward-distances}
hist(data_trunc$forw_dist, main = "", xlab = "Forward distance (m)")
boxplot(data_trunc$forw_dist, ylab = "Forward distance (m)")
```


If ouliers are detected in the forward distances, they can be removed with the following code (optional):

```{r}
# ystart = max(data_trunc$forw_dist) # change this to the desired truncation distance if necessary, e.g. 
ystart = 150
data_trunc <- 
  data_trunc %>% 
  filter(forw_dist <= ystart)
```




## Model fitting and estimated groups in the surveyed region

We now fit 2D distance sampling model using multiple initial value to avoid local *minima* in the deviance (Elenga et al 2020) and we obtain the estimates of the detection probabilities and the number of groups with bootstrap confidence intervals:

```{r model-fitting}
seed_no <- set.seed(params$seed_no)
#### Model fitting
y = data_trunc$forw_dist
x = data_trunc$perp_dist
hr = h.RE # h.yTRE not compatible with pi.sigmoI
# these functions work: h.RE, h.IP, h.SS, h.okamura
pi.x = pi.sigmo
# functions tested and working with h.RE: pi.sigmo, pi.CHN, pi.TN
ystart = ceiling(max(y))
w = ceiling(max(x))
length.b = 2
debug=FALSE

 FIT=list(); dev=NULL
 for (m in 1:10) {
   set.seed(params$seed_no)
   pars = rnorm(4, c(0.25,0.25,-4,-1), 3)
   set.seed(params$seed_no)
   tmp0 <- tryCatch.W.E (
     fityx(y,x,pars[1:length.b],
           hr,ystart,pi.x,pars[(length.b+1):length(pars)],w,control=list(),
           hessian=TRUE,corrFlag=0.7,debug=FALSE)
   )
   fit = NA
   if(! "error" %in% class(tmp0$value)) {
     fit <- tmp0$value
     fit$vcov <-  matrix(Matrix::nearPD(fit$vcov)$mat,4,4)
   }
   FIT[[m]] = fit
   if(is.na(fit[1])) dev=c(dev, 1e12) else dev = c(dev, fit$val)
 }
 fitVU = FIT[[which.min(dev)]]
 tabVU = matrix(NA,2,3)
 if(is.na(fitVU[1])) tabVU = matrix(NA,2,3) else {
   # set.seed(10)
   tmp1 <- tryCatch.W.E (boot(fitVU))
 if(! "error" %in% class(tmp1$value))  tabVU=tmp1$value
 }
tabVU
if(!is.numeric(unlist(tabVU))) print("error, change seed_no to any random number")
save(fitVU, file = "output/fitVU.RData", compress = FALSE)
```

```{r}
tryCatch.W.E(plotfit.x(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
```

```{r}
tryCatch.W.E(plotfit.x.red(x[x<=w],fitVU,nclass=20,nint=100));rug(x[x<=w])
# vedere https://github.com/david-borchers/LT2D/blob/master/inst/FitsForPaper.r
# linea nera sigmoide = distribuzione reale animali
# linea grigia = detection osservata
# linea tratteggiata = detection corretta tenendo conto della risposta comportamentale
```


We perform checks on the model, to verify the goodness of fit:

```{r gof-tests}
fName = "h1"
GoFx(fitVU,plot=TRUE)$pvals
plotfit.y(y[x<=w & y<=ystart],x,fitVU,nclass=20);rug(x=y[x<=w])
plotfit.smoothfy(fitVU,nclass=32);rug(x=y[x<=w])
GoFy_vlm(fitVU,plot=TRUE)$pvals # brillantemente risolto

plotfit.smoothfy(fitVU,xmax=199)
``` 
and we finally summarise the results on the detection probability and the number of groups in the surveyed region:

```{r detection-prob}
#EHSW:
# phatInterval(fitVU) %>% 
#   dplyr::select(-interval)

LT2D::phatModels(modList = FIT[1], n=length(data$cluster_size))
```
Indeed, the estimated number of groups in the surveyed region is estimated by dividing the number of observed groups for the detection probability:

```{r groups}
length(data$cluster_size)/(phatInterval(fitVU))[1] -> no_groups
names(no_groups) <- "no_groups"
(no_groups/(2*(w/1000)*sum(data$transect_length))) -> dens_groups_km2
names(dens_groups_km2) <- "dens_groups_km2"
cbind(no_groups, dens_groups_km2)
# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
# as.data.frame(phatInterval(fitVU)*w) %>% 
#   dplyr::select(-interval) %>% 
#   dplyr::rename(Nhat = phat,
#                 CV.Nhat = CV.phat)# riassegnare i nomi alla tabella, eliminando interval restano: Nhat dei gruppi nella regione indagata (w), CV del numero di gruppi e limiti dell'intervallo
# p(0):
# p0.n=tryCatch.W.E(1-Sy(0,0,ystart,fitVU$b,h1));p0.n
```


## Cluster size stats and estimated number of individuals with CV

In order to estimate the number of individuals, we now consider the cluster size data, summarising them and calculating the cluster size standard deviation:

```{r}
data_clustersize <- 
  data %>% 
  filter(detected != 0,
         perp_dist != "NA",
         forw_dist != "NA",
         perp_dist <= w,
         forw_dist <= ystart)
data_clustersize$forw_dist <- abs(data_clustersize$forw_dist)
# mean(data_clustersize$cluster_size)
summary(data_clustersize$cluster_size)
print("Cluster size standard deviation:")
sd(data_clustersize$cluster_size)
```


```{r}
no_groups*mean(data_clustersize$cluster_size) -> abund_survey_individuals
cv2_detfunc <- (phatInterval(fitVU)[2])^2
cv2_clustersize <- (sd(data_clustersize$cluster_size)/mean(data_clustersize$cluster_size))^2
data %>% 
  mutate(transetto = factor(transect)) %>%
  dplyr::group_by(transect) %>% 
  dplyr::summarise(no_groups_transect = sum(detected),
                   transect_length = mean(transect_length)) %>% 
  mutate(encounter_rate = no_groups_transect/transect_length) -> res
res
res$no_groups_transect
cv2_transetti <- (sd(res$encounter_rate)/mean(res$encounter_rate))^2
(cv_tot <- sqrt(cv2_detfunc + cv2_clustersize + cv2_transetti))
  
```




```{r}
data_transects <- read_excel("data/impala_vlm.xlsx", 
                             sheet="template_dataset",
                             col_types = c(rep("numeric", 3),
                                 "date",
                                 "text", "text",
                                 rep("numeric", 5)))
data_transects %>% 
  distinct(transect, transect_length) -> data_transects_unique
### Population density
transect.lengths = data_transects_unique$transect_length
sum(transect.lengths)*2*w/1000 # area indagata

phatInterval(fitVU)*w -> abund_survey # num gruppi, i nomi delle colonne sono da modificare

abund_survey[1]/sum(transect.lengths)/(fitVU$w/1000) -> dens_gruppi_km2
names(dens_gruppi_km2) <- "no_gruppi_km2"
abund_survey_individuals[1]/sum(transect.lengths)/(fitVU$w/1000) -> dens_ind_km2 # individui
names(dens_ind_km2) <- "no_ind_km2"

# dividendo per 1000 la distanza di troncatura, si riporta l'unità di misura per la densità in km2
cbind(dens_gruppi_km2, dens_ind_km2)
```



```{r, eval=FALSE}
openGraph(h=3,w=12)
par(mfrow=c(1,3))
pdlab="Perpendicular distance"
fdlab="Distance along transect"
plot(jitter(y,1,0),jitter(x),pch="+",ylab=pdlab,xlab=fdlab,main="")
hist(y,breaks=seq(0,max(na.omit(y)),length=16),xlab=fdlab,main="")
hist(x,breaks=seq(0,max(na.omit(x)),length=12),xlab=pdlab,main="")
```

<!-- Per DSM poi vedi anche: -->
<!-- C:/Users/valen/OneDrive - ISPRA/Articoli_in_prep/Svezia-DeerCompetition/svezia-analisi2018/2021-04-paper/Appendix2-2019-05-16.Rmd -->
